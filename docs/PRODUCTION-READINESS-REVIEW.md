# üîç Production Readiness Review - ExploreSG Auth Service

## Kubernetes/EKS Deployment Assessment

**Review Date:** October 11, 2025  
**Service Version:** 0.0.1-SNAPSHOT  
**Target Environment:** Kubernetes (K8s) / Amazon EKS  
**Reviewer:** GitHub Copilot  
**Status:** ‚ö†Ô∏è NEEDS ATTENTION - Several critical issues identified

---

## Executive Summary

The ExploreSG Auth Service has a **solid foundation** with good documentation, externalized configuration, and containerization. However, there are **CRITICAL production blockers** that must be addressed before deploying to production Kubernetes/EKS.

### Overall Readiness Score: 6.5/10

| Category                     | Score | Status               |
| ---------------------------- | ----- | -------------------- |
| üèóÔ∏è Architecture & Design     | 8/10  | ‚úÖ Good              |
| üê≥ Container & Docker        | 7/10  | ‚ö†Ô∏è Needs Improvement |
| ‚ò∏Ô∏è Kubernetes Configuration  | 6/10  | ‚ö†Ô∏è Major Issues      |
| üîí Security                  | 5/10  | üö® Critical Issues   |
| üìä Observability             | 6/10  | ‚ö†Ô∏è Needs Improvement |
| üöÄ Performance & Scalability | 6/10  | ‚ö†Ô∏è Needs Improvement |
| üíæ Data & State Management   | 7/10  | ‚ö†Ô∏è Needs Attention   |
| üîÑ CI/CD & Deployment        | 8/10  | ‚úÖ Good              |
| üìö Documentation             | 9/10  | ‚úÖ Excellent         |

---

## üö® CRITICAL ISSUES (Must Fix Before Production)

### 1. üî¥ CRITICAL: Hardcoded Secrets in Kubernetes Manifests

**File:** `kubernetes/deployment.yaml`

```yaml
stringData:
  SPRING_DATASOURCE_USERNAME: "exploresguser"
  SPRING_DATASOURCE_PASSWORD: "CHANGE_ME_IN_PRODUCTION" # ‚ö†Ô∏è CRITICAL
  JWT_SECRET_KEY: "CHANGE_ME_IN_PRODUCTION" # ‚ö†Ô∏è CRITICAL
  OAUTH2_JWT_AUDIENCES: "YOUR_GOOGLE_CLIENT_ID" # ‚ö†Ô∏è CRITICAL
```

**Issues:**

- Passwords and secrets are plaintext in YAML files
- These will be committed to version control
- Anyone with repository access can see production credentials

**Solution:**

```yaml
# DO NOT store secrets in YAML files!
# Option 1: Use Kubernetes External Secrets Operator with AWS Secrets Manager
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: auth-service-secrets
  namespace: exploresg
spec:
  refreshInterval: 1h
  secretStoreRef:
    name: aws-secrets-manager
    kind: SecretStore
  target:
    name: auth-service-secrets
  data:
    - secretKey: SPRING_DATASOURCE_PASSWORD
      remoteRef:
        key: exploresg/auth-service/db-password
    - secretKey: JWT_SECRET_KEY
      remoteRef:
        key: exploresg/auth-service/jwt-secret

# Option 2: Use kubectl to create secrets from CLI (not committed)
kubectl create secret generic auth-service-secrets \
  --from-literal=SPRING_DATASOURCE_PASSWORD='<actual-password>' \
  --from-literal=JWT_SECRET_KEY='<actual-jwt-secret>' \
  --namespace=exploresg

# Option 3: Use AWS Parameter Store with IAM roles (EKS)
# Configure IRSA (IAM Roles for Service Accounts)
```

**Priority:** üî¥ CRITICAL - Fix immediately

---

### 2. üî¥ CRITICAL: Insecure Docker Image Configuration

**File:** `Dockerfile`

```dockerfile
FROM openjdk:17-jdk-slim
WORKDIR /app
COPY --from=builder /app/target/*.jar app.jar
EXPOSE 8080
ENTRYPOINT ["java", "-jar", "app.jar"]
```

**Issues:**

1. **Running as root user** - Major security vulnerability
2. **No JVM tuning** - Will crash under load
3. **No health check** - Docker doesn't know if app is healthy
4. **Inefficient JDK** - Using full JDK instead of JRE
5. **Missing security scanning** - No vulnerability checks

**Solution:**

```dockerfile
# ---- Build Stage ----
FROM maven:3.9.6-eclipse-temurin-17 AS builder
WORKDIR /app
COPY pom.xml .
COPY src ./src
RUN mvn clean package -DskipTests

# ---- Run Stage ----
FROM eclipse-temurin:17-jre-alpine
# Create non-root user
RUN addgroup -g 1001 -S appuser && \
    adduser -u 1001 -S appuser -G appuser

WORKDIR /app

# Copy JAR with specific permissions
COPY --from=builder --chown=appuser:appuser /app/target/*.jar app.jar

# Switch to non-root user
USER appuser

# Set JVM options for containerized environment
ENV JAVA_OPTS="-XX:+UseContainerSupport \
               -XX:MaxRAMPercentage=75.0 \
               -XX:InitialRAMPercentage=50.0 \
               -XX:+UseG1GC \
               -XX:+HeapDumpOnOutOfMemoryError \
               -XX:HeapDumpPath=/tmp/heapdump.hprof \
               -Djava.security.egd=file:/dev/./urandom"

EXPOSE 8080

# Add health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=60s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost:8080/actuator/health || exit 1

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

**Priority:** üî¥ CRITICAL - Fix immediately

---

### 3. üî¥ CRITICAL: No Database Migration Strategy

**Issue:** Using `spring.jpa.hibernate.ddl-auto=update` in production

**Problems:**

- Schema changes are not versioned
- No rollback capability
- Can cause data loss
- Cannot track changes across environments
- Breaks in multi-instance deployments

**Solution:**

1. **Add Flyway or Liquibase to `pom.xml`:**

```xml
<dependency>
    <groupId>org.flywaydb</groupId>
    <artifactId>flyway-core</artifactId>
</dependency>
<dependency>
    <groupId>org.flywaydb</groupId>
    <artifactId>flyway-database-postgresql</artifactId>
</dependency>
```

2. **Update `application-prod.properties`:**

```properties
# Change from 'update' to 'validate'
spring.jpa.hibernate.ddl-auto=validate

# Enable Flyway
spring.flyway.enabled=true
spring.flyway.baseline-on-migrate=true
spring.flyway.locations=classpath:db/migration
```

3. **Create migration scripts:** `src/main/resources/db/migration/`

```sql
-- V1__initial_schema.sql
CREATE TABLE IF NOT EXISTS app_user (
    id BIGSERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    role VARCHAR(255) NOT NULL,
    ...
);

-- V2__add_user_profile.sql
CREATE TABLE IF NOT EXISTS user_profile (
    id BIGINT PRIMARY KEY REFERENCES app_user(id),
    ...
);
```

**Priority:** üî¥ CRITICAL - Required for production

---

### 4. üü† HIGH: Hardcoded CORS Origins in SecurityConfig

**File:** `src/main/java/com/exploresg/authservice/config/SecurityConfig.java`

```java
configuration.setAllowedOrigins(List.of("http://localhost:3000"));  // ‚ö†Ô∏è HARDCODED
```

**Issues:**

- Hardcoded to localhost only
- Won't work in production
- Not reading from environment variables

**Solution:**

```java
@Configuration
@EnableWebSecurity
@RequiredArgsConstructor
@EnableMethodSecurity
public class SecurityConfig {

    @Value("${cors.allowed-origins}")
    private String allowedOrigins;

    @Bean
    public CorsConfigurationSource corsConfigurationSource() {
        CorsConfiguration configuration = new CorsConfiguration();
        // Split comma-separated origins from environment variable
        configuration.setAllowedOrigins(
            Arrays.asList(allowedOrigins.split(","))
        );
        configuration.setAllowedMethods(List.of("GET", "POST", "PUT", "DELETE", "OPTIONS"));
        configuration.setAllowedHeaders(List.of("Authorization", "Content-Type"));
        configuration.setAllowCredentials(true);

        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
        source.registerCorsConfiguration("/**", configuration);
        return source;
    }
}
```

**Priority:** üü† HIGH - Fix before deployment

---

### 5. üü† HIGH: Missing Resource Limits in Kubernetes

**Issue:** Resource requests are set but limits need tuning

**Current Configuration:**

```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "250m"
  limits:
    memory: "1Gi"
    cpu: "500m"
```

**Problems:**

- Limits are too low for production traffic
- No testing/benchmarking done
- May cause OOMKilled errors
- CPU throttling possible

**Solution:**

1. **Run load testing first** to determine actual resource needs
2. **Start with higher limits:**

```yaml
resources:
  requests:
    memory: "1Gi" # Doubled for safety
    cpu: "500m" # Doubled for safety
  limits:
    memory: "2Gi" # Allow headroom
    cpu: "1000m" # Full core available
```

3. **Monitor and adjust** based on actual usage with Prometheus/Grafana

**Priority:** üü† HIGH - Test and tune before production

---

## ‚ö†Ô∏è MEDIUM PRIORITY ISSUES

### 6. ‚ö†Ô∏è MEDIUM: No Distributed Tracing

**Missing:**

- OpenTelemetry/Jaeger/Zipkin integration
- Request tracing across services
- Distributed transaction monitoring

**Solution:**

Add to `pom.xml`:

```xml
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-otel</artifactId>
</dependency>
<dependency>
    <groupId>io.opentelemetry</groupId>
    <artifactId>opentelemetry-exporter-otlp</artifactId>
</dependency>
```

Add to `application-prod.properties`:

```properties
management.tracing.sampling.probability=1.0
management.otlp.tracing.endpoint=http://jaeger:4318/v1/traces
```

---

### 7. ‚ö†Ô∏è MEDIUM: Insufficient Health Check Configuration

**Current:** Basic Spring Boot Actuator enabled

**Missing:**

- Custom health indicators
- Dependency health checks (database, external APIs)
- Detailed readiness probes

**Solution:**

Create custom health indicators:

```java
@Component
public class DatabaseHealthIndicator implements HealthIndicator {

    @Autowired
    private DataSource dataSource;

    @Override
    public Health health() {
        try (Connection conn = dataSource.getConnection()) {
            Statement stmt = conn.createStatement();
            stmt.executeQuery("SELECT 1");
            return Health.up()
                .withDetail("database", "PostgreSQL")
                .withDetail("status", "reachable")
                .build();
        } catch (SQLException e) {
            return Health.down()
                .withDetail("error", e.getMessage())
                .build();
        }
    }
}
```

Update K8s probes:

```yaml
livenessProbe:
  httpGet:
    path: /actuator/health/liveness
    port: 8080
  initialDelaySeconds: 120 # Increased for startup
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3
  successThreshold: 1

readinessProbe:
  httpGet:
    path: /actuator/health/readiness
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3
  successThreshold: 1

startupProbe: # Add startup probe
  httpGet:
    path: /actuator/health/liveness
    port: 8080
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 3
  failureThreshold: 30 # 5 minutes for startup
```

---

### 8. ‚ö†Ô∏è MEDIUM: No Rate Limiting Implementation

**Current:** Only nginx ingress rate limiting annotation

**Issues:**

- No application-level rate limiting
- Can be bypassed if accessed directly
- No per-user/per-IP limits

**Solution:**

Add Bucket4j for rate limiting:

```xml
<dependency>
    <groupId>com.bucket4j</groupId>
    <artifactId>bucket4j-core</artifactId>
    <version>8.7.0</version>
</dependency>
```

Implement rate limiting filter:

```java
@Component
public class RateLimitingFilter extends OncePerRequestFilter {

    private final Map<String, Bucket> cache = new ConcurrentHashMap<>();

    @Override
    protected void doFilterInternal(HttpServletRequest request,
                                    HttpServletResponse response,
                                    FilterChain filterChain) throws ServletException, IOException {
        String key = getClientIP(request);
        Bucket bucket = resolveBucket(key);

        if (bucket.tryConsume(1)) {
            filterChain.doFilter(request, response);
        } else {
            response.setStatus(429);
            response.getWriter().write("Too many requests");
        }
    }

    private Bucket resolveBucket(String key) {
        return cache.computeIfAbsent(key, k ->
            Bucket.builder()
                .addLimit(Bandwidth.classic(100, Refill.intervally(100, Duration.ofMinutes(1))))
                .build()
        );
    }
}
```

---

### 9. ‚ö†Ô∏è MEDIUM: Missing Structured Logging

**Current:** Simple console logging

**Needed for Production:**

- JSON structured logging
- Log aggregation ready (ELK/CloudWatch)
- Correlation IDs
- Request context

**Solution:**

Add Logback JSON encoder:

```xml
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>7.4</version>
</dependency>
```

Create `logback-spring.xml`:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <springProfile name="prod">
        <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
            <encoder class="net.logstash.logback.encoder.LogstashEncoder">
                <fieldNames>
                    <timestamp>timestamp</timestamp>
                    <message>message</message>
                    <logger>logger</logger>
                    <thread>thread</thread>
                    <level>level</level>
                </fieldNames>
            </encoder>
        </appender>
        <root level="INFO">
            <appender-ref ref="STDOUT" />
        </root>
    </springProfile>
</configuration>
```

---

### 10. ‚ö†Ô∏è MEDIUM: No Circuit Breaker Pattern

**Issue:** If external services (Google OAuth) fail, entire app can hang

**Solution:**

Add Resilience4j:

```xml
<dependency>
    <groupId>io.github.resilience4j</groupId>
    <artifactId>resilience4j-spring-boot3</artifactId>
    <version>2.1.0</version>
</dependency>
```

Apply circuit breaker to OAuth calls:

```java
@Service
@RequiredArgsConstructor
public class AuthenticationService {

    @CircuitBreaker(name = "googleOAuth", fallbackMethod = "fallbackAuth")
    @Retry(name = "googleOAuth")
    @TimeLimiter(name = "googleOAuth")
    public AuthResponse authenticateWithGoogle(String idToken) {
        // OAuth logic
    }

    private AuthResponse fallbackAuth(String idToken, Exception e) {
        log.error("Google OAuth unavailable", e);
        throw new ServiceUnavailableException("Authentication service temporarily unavailable");
    }
}
```

Configuration:

```yaml
resilience4j:
  circuitbreaker:
    instances:
      googleOAuth:
        registerHealthIndicator: true
        slidingWindowSize: 10
        failureRateThreshold: 50
        waitDurationInOpenState: 30s
```

---

## üîµ LOW PRIORITY (Nice to Have)

### 11. Service Mesh Integration

**Consider:** Istio or AWS App Mesh for:

- mTLS between services
- Advanced traffic management
- Observability

### 12. Database Connection Pooling Tuning

**Current:** Using default HikariCP settings

**Optimize for production:**

```properties
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=10
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.idle-timeout=600000
spring.datasource.hikari.max-lifetime=1800000
spring.datasource.hikari.leak-detection-threshold=60000
```

### 13. API Documentation Endpoint Security

**Current:** Swagger UI exposed in production

**Solution:**

```yaml
# In SecurityConfig
.requestMatchers("/swagger-ui/**", "/v3-api-docs/**")
.hasRole("ADMIN") # Restrict to admins only
```

---

## ‚úÖ STRENGTHS (What's Already Good)

### 1. ‚úÖ Excellent Documentation

- Comprehensive README
- Detailed environment setup guide
- Cloud deployment documentation
- Well-documented code

### 2. ‚úÖ Externalized Configuration

- Environment variables properly used
- Multiple profiles (dev/staging/prod)
- No secrets in main application properties

### 3. ‚úÖ Good CI/CD Foundation

- GitHub Actions workflows
- Automated testing
- Docker image building

### 4. ‚úÖ Security Best Practices (Mostly)

- JWT authentication
- Spring Security configured
- CORS configuration
- OAuth2 integration

### 5. ‚úÖ Monitoring Ready

- Spring Boot Actuator enabled
- Prometheus metrics exposed
- Health endpoints configured

### 6. ‚úÖ Horizontal Pod Autoscaling

- HPA configured
- Metrics-based scaling
- Min/max replicas defined

---

## üìã PRE-DEPLOYMENT CHECKLIST

### Critical (Must Complete)

- [ ] Remove hardcoded secrets from Kubernetes manifests
- [ ] Implement AWS Secrets Manager integration (or K8s sealed secrets)
- [ ] Fix Dockerfile to run as non-root user
- [ ] Add JVM tuning for containerized environment
- [ ] Implement database migration strategy (Flyway/Liquibase)
- [ ] Fix hardcoded CORS origins
- [ ] Generate strong JWT secret (min 256-bit)
- [ ] Load test and tune resource limits
- [ ] Set up RDS/managed PostgreSQL with encryption
- [ ] Configure SSL/TLS for database connections

### High Priority

- [ ] Add distributed tracing (OpenTelemetry)
- [ ] Implement custom health indicators
- [ ] Add application-level rate limiting
- [ ] Implement structured JSON logging
- [ ] Add circuit breaker for external services
- [ ] Configure log aggregation (CloudWatch/ELK)
- [ ] Set up monitoring dashboards (Grafana)
- [ ] Configure alerts (CPU, memory, errors, latency)
- [ ] Create runbook for incident response
- [ ] Perform security scanning (Snyk, Trivy)

### Medium Priority

- [ ] Implement graceful shutdown
- [ ] Add request tracing/correlation IDs
- [ ] Configure backup strategy for database
- [ ] Set up disaster recovery plan
- [ ] Document scaling policies
- [ ] Create performance benchmarks
- [ ] Set up staging environment
- [ ] Conduct penetration testing
- [ ] Review and harden network policies

### Nice to Have

- [ ] Consider service mesh (Istio/Linkerd)
- [ ] Implement caching layer (Redis)
- [ ] Add API versioning strategy
- [ ] Set up chaos engineering tests
- [ ] Create load testing automation
- [ ] Add A/B testing capability

---

## üõ†Ô∏è RECOMMENDED ARCHITECTURE IMPROVEMENTS

### 1. Multi-AZ Deployment for High Availability

```yaml
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - exploresg-auth-service
          topologyKey: topology.kubernetes.io/zone
```

### 2. Pod Disruption Budget

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: auth-service-pdb
  namespace: exploresg
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: exploresg-auth-service
```

### 3. Network Policies

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: auth-service-network-policy
  namespace: exploresg
spec:
  podSelector:
    matchLabels:
      app: exploresg-auth-service
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
      ports:
        - protocol: TCP
          port: 8080
  egress:
    - to:
        - namespaceSelector: {}
      ports:
        - protocol: TCP
          port: 5432 # PostgreSQL
        - protocol: TCP
          port: 443 # HTTPS for Google OAuth
```

---

## üéØ DEPLOYMENT ROADMAP

### Phase 1: Critical Fixes (1-2 weeks)

1. Fix Dockerfile security issues
2. Implement secrets management
3. Add database migrations
4. Fix CORS configuration
5. Load test and tune resources

### Phase 2: Observability (1 week)

1. Implement structured logging
2. Add distributed tracing
3. Set up monitoring dashboards
4. Configure alerts

### Phase 3: Resilience (1 week)

1. Add circuit breakers
2. Implement rate limiting
3. Add health indicators
4. Configure graceful shutdown

### Phase 4: Production Deployment (1 week)

1. Deploy to staging
2. Run acceptance tests
3. Conduct security audit
4. Deploy to production (blue-green)
5. Monitor and validate

**Total Estimated Time: 4-5 weeks**

---

## üí∞ ESTIMATED AWS COSTS (EKS Deployment)

### Monthly Estimate (Production)

| Resource                  | Configuration             | Monthly Cost    |
| ------------------------- | ------------------------- | --------------- |
| EKS Cluster               | 1 cluster                 | $73             |
| EC2 Nodes                 | 3x t3.medium (2vCPU, 4GB) | ~$75            |
| RDS PostgreSQL            | db.t3.small (HA)          | ~$60            |
| Application Load Balancer | 1 ALB                     | ~$25            |
| NAT Gateway               | 1 gateway                 | ~$35            |
| Data Transfer             | 100GB/month               | ~$10            |
| Secrets Manager           | 5 secrets                 | ~$2             |
| CloudWatch Logs           | 10GB retention            | ~$5             |
| **Total**                 |                           | **~$285/month** |

_Note: Costs vary by region and actual usage_

---

## üìû SUPPORT & NEXT STEPS

### Immediate Actions Required:

1. **Review this document** with your team
2. **Prioritize critical issues** (sections 1-5)
3. **Create Jira/GitHub issues** for each item
4. **Assign owners** for each fix
5. **Set target dates** for completion
6. **Schedule code review** after fixes

### Questions to Answer Before Deployment:

1. What is your expected traffic volume?
2. What are your SLA requirements (uptime, latency)?
3. What is your budget for infrastructure?
4. Do you have a DevOps/SRE team?
5. What monitoring tools do you prefer?
6. Do you need multi-region deployment?
7. What is your disaster recovery requirement?

---

## üìö REFERENCES

- [AWS EKS Best Practices](https://aws.github.io/aws-eks-best-practices/)
- [Spring Boot Production Best Practices](https://docs.spring.io/spring-boot/docs/current/reference/html/deployment.html)
- [OWASP Top 10](https://owasp.org/www-project-top-ten/)
- [12-Factor App](https://12factor.net/)
- [Kubernetes Security Best Practices](https://kubernetes.io/docs/concepts/security/overview/)

---

**Report Generated:** October 11, 2025  
**Version:** 1.0  
**Status:** Comprehensive Review Complete

For questions or clarifications, please reach out to your DevOps/SRE team or create an issue in the repository.
